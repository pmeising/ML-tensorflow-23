{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_qgtyZ9yyWt"
      },
      "source": [
        "# Model Definition and Evaluation\n",
        "## Table of Contents\n",
        "1. [Model Selection](#model-selection)\n",
        "2. [Feature Engineering](#feature-engineering)\n",
        "3. [Hyperparameter Tuning](#hyperparameter-tuning)\n",
        "4. [Implementation](#implementation)\n",
        "5. [Evaluation Metrics](#evaluation-metrics)\n",
        "6. [Comparative Analysis](#comparative-analysis)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wxyJIa6UyyWw"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from google.colab import files, drive\n",
        "import zipfile\n",
        "import shutil\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten, MaxPooling2D, Conv2D\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from collections import Counter\n",
        "import random\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import json\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the zip file in Google Drive\n",
        "zip_file_path = '/content/drive/MyDrive/ML_Tensorflow/phytoplankton_labeled.zip'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/dataset')\n",
        "\n",
        "data_dir = '/content/dataset/labeled_20201020'\n",
        "\n",
        "base_dir = '/content/dataset/groups'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfPRN-ykzMHq",
        "outputId": "507c6bcd-b9fd-442e-c6ab-76422453325d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import models\n",
        "\n",
        "model_dir = '/content/drive/MyDrive/ML_Tensorflow/models/'\n",
        "\n",
        "child_models = [load_model(model_dir + 'model_0_9.h5'), load_model(model_dir + 'model_10_19.h5'), load_model(model_dir + 'model_20_29.h5'), load_model(model_dir + 'model_30_39.h5'), load_model(model_dir + 'model_40_49.h5')]\n",
        "\n",
        "parent_model = load_model(model_dir + 'model_parent.h5')\n",
        "\n",
        "print(\"Finished loading the models.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQMqPWxty52_",
        "outputId": "ff60bb1f-cf18-4d70-b0dc-7f1bd12064a0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished loading the models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7fvZmcqyyWy"
      },
      "source": [
        "## Model Selection\n",
        "\n",
        "[Discuss the type(s) of models you consider for this task, and justify the selection.]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wa7c96dWyyWy"
      },
      "source": [
        "## Feature Engineering\n",
        "\n",
        "[Describe any additional feature engineering you've performed beyond what was done for the baseline model.]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nih__A-kyyWy",
        "outputId": "30dbe875-f443-4575-b6f5-4c7d2571dbd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in dataset: 63074\n"
          ]
        }
      ],
      "source": [
        "# Initialize lists to hold image paths and labels\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "# Iterate over each sub-directory in the dataset directory\n",
        "for label_dir in os.listdir(data_dir):\n",
        "    label_dir_full_path = os.path.join(data_dir, label_dir)\n",
        "\n",
        "    # Check if it's a directory\n",
        "    if os.path.isdir(label_dir_full_path):\n",
        "        # Iterate over each image in the sub-directory\n",
        "        for image_file in os.listdir(label_dir_full_path):\n",
        "            # Construct the full path for the image file\n",
        "            image_file_full_path = os.path.join(label_dir_full_path, image_file)\n",
        "\n",
        "            # Check if it's a file and not a directory\n",
        "            if os.path.isfile(image_file_full_path):\n",
        "                # Add the image path and label to the lists\n",
        "                image_paths.append(image_file_full_path)\n",
        "                labels.append(label_dir) # assuming label is the directory name\n",
        "\n",
        "# Now you can split the image paths and labels into train, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(image_paths, labels, test_size=0.3, stratify=labels, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
        "\n",
        "unique_classes = np.unique(labels)\n",
        "\n",
        "# Generate a dictionary mapping numerical values to class names\n",
        "class_to_idx = {class_name: idx for idx, class_name in enumerate(unique_classes)}\n",
        "\n",
        "# Generate a dictionary mapping numerical values back to class names\n",
        "idx_to_class = {idx: class_name for class_name, idx in class_to_idx.items()}\n",
        "\n",
        "print(f\"Number of images in dataset: {len(image_paths)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "# Convert the lists into DataFrames\n",
        "train_df = pd.DataFrame({'filepath': X_train, 'label': y_train})\n",
        "val_df = pd.DataFrame({'filepath': X_val, 'label': y_val})\n",
        "test_df = pd.DataFrame({'filepath': X_test, 'label': y_test})\n",
        "\n",
        "# Initialize ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create the generator\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='filepath',\n",
        "    y_col='label',\n",
        "    target_size=(160, 160),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddHeXqAlC5nz",
        "outputId": "08b21117-658b-4b59-dbe9-0fd2af58b9b1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9462 validated image filenames belonging to 50 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict class for a batch of images\n",
        "def predict_classes(images, parent_model, child_models):\n",
        "    # Predict the group using the parent model\n",
        "    group_probabilities = parent_model.predict(images)\n",
        "    groups = np.argmax(group_probabilities, axis=1)\n",
        "    print(f\"Image was predicted to belong to group {groups}.\")\n",
        "\n",
        "    final_predictions = []\n",
        "\n",
        "    # Iterate over each image and its predicted group\n",
        "    for image, group in zip(images, groups):\n",
        "        # Prepare image for prediction (reshape to include batch dimension)\n",
        "        image_batch = np.expand_dims(image, axis=0)\n",
        "\n",
        "        # Predict the final class using the corresponding child model\n",
        "        final_class_probabilities = child_models[group].predict(image_batch)\n",
        "        final_class = np.argmax(final_class_probabilities, axis=1)[0]\n",
        "        final_predictions.append(final_class)\n",
        "\n",
        "    return final_predictions\n",
        "\n",
        "# Predicting on test set\n",
        "predictions = []\n",
        "for images, _ in test_generator:\n",
        "    batch_predictions = predict_classes(images, parent_model, child_models)\n",
        "    predictions.extend(batch_predictions)\n",
        "\n",
        "    # Break the loop if we have predicted for all images\n",
        "    if len(predictions) >= len(test_df) or len(predictions) >= 5:\n",
        "        break\n",
        "\n",
        "# Truncate predictions to match the length of test set (in case of last partial batch)\n",
        "predictions = predictions[:len(test_df)]\n",
        "\n",
        "# Convert labels back to original format if necessary\n",
        "# e.g., labels = [class_mapping[p] for p in predictions]\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = sum(p == actual for p, actual in zip(predictions, test_df['label']))\n",
        "accuracy = correct_predictions / len(test_df)\n",
        "print(f\"Accuracy on test set: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5RKpwg4_Kx0",
        "outputId": "ed7aae1f-14e5-4863-8f03-48943f398b8f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 761ms/step\n",
            "Image was predicted to belong to group [3 4 1 1 1 2 0 4 1 1 1 3 3 2 2 1 3 1 0 1 0 2 2 4 1 4 4 0 3 1 4 4].\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "Accuracy on test set: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_class_name_from_index(index, idx_to_class):\n",
        "    \"\"\"\n",
        "    Get the class name corresponding to a numerical index.\n",
        "\n",
        "    :param index: The numerical index (prediction from the model).\n",
        "    :param idx_to_class: A dictionary mapping indices to class names.\n",
        "    :return: The corresponding class name.\n",
        "    \"\"\"\n",
        "    return idx_to_class.get(index, \"Unknown\")\n",
        "\n",
        "def load_and_preprocess_image(image_path, target_size=(160, 160)):\n",
        "    \"\"\"\n",
        "    Load an image and preprocess it for model prediction.\n",
        "\n",
        "    :param image_path: Path to the image file.\n",
        "    :param target_size: The target size to which the image is resized. Default is (160, 160).\n",
        "    :return: Preprocessed image.\n",
        "    \"\"\"\n",
        "    # Open the image file\n",
        "    with Image.open(image_path) as img:\n",
        "        # Resize the image\n",
        "        img = img.resize(target_size)\n",
        "\n",
        "        # Convert the image to a numpy array\n",
        "        image_array = np.array(img)\n",
        "\n",
        "        # Ensure the image has 3 channels (RGB)\n",
        "        if image_array.ndim == 2:\n",
        "            image_array = np.stack((image_array,)*3, axis=-1)\n",
        "        elif image_array.shape[2] == 4:\n",
        "            image_array = image_array[..., :3]\n",
        "\n",
        "        # Normalize the image\n",
        "        image_array = image_array / 255.0\n",
        "\n",
        "    return image_array\n",
        "\n",
        "# Function to predict the class for a single image\n",
        "def predict_class(image, parent_model, child_models):\n",
        "    # Prepare image for prediction (adding batch dimension)\n",
        "    image_batch = np.expand_dims(image, axis=0)\n",
        "\n",
        "    # Predict the group using the parent model\n",
        "    group_probabilities = parent_model.predict(image_batch)\n",
        "    group = np.argmax(group_probabilities, axis=1)[0]\n",
        "    print(f\"Image classified as belonging to group {group}\")\n",
        "\n",
        "    # Select the child model based on the predicted group\n",
        "    child_model = child_models[group]\n",
        "\n",
        "    # Predict the final class using the child model\n",
        "    final_class_probabilities = child_model.predict(image_batch)\n",
        "    final_class = np.argmax(final_class_probabilities, axis=1)[0]\n",
        "\n",
        "    return final_class\n",
        "\n",
        "# Predict for 5 images from the test set\n",
        "num_samples_to_predict = 20\n",
        "sample_predictions = []\n",
        "\n",
        "for i in range(num_samples_to_predict):\n",
        "    image_path = test_df.iloc[i]['filepath']  # Get the image path\n",
        "    true_label = test_df.iloc[i]['label']  # Get the true label for comparison\n",
        "    image = load_and_preprocess_image(image_path)  # Load and preprocess the image\n",
        "\n",
        "    prediction = predict_class(image, parent_model, child_models)  # Predict the class\n",
        "    sample_predictions.append((image_path, prediction, true_label))  # Store the results\n",
        "\n",
        "# Display the predictions\n",
        "for img_path, pred, true in sample_predictions:\n",
        "    class_name = get_class_name_from_index(pred, idx_to_class)\n",
        "    print(f\"Predicted class: {class_name}, True class: {true}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BN6pszBQHz3e",
        "outputId": "f8f1371e-709f-46cb-e886-ac85b4feb354"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 43ms/step\n",
            "Image classified as belonging to group 3\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "Image classified as belonging to group 4\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "Image classified as belonging to group 1\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Image classified as belonging to group 1\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "Image classified as belonging to group 1\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "Image classified as belonging to group 1\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "Image classified as belonging to group 0\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "Image classified as belonging to group 1\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "Image classified as belonging to group 1\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "Image classified as belonging to group 1\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Image classified as belonging to group 1\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Image classified as belonging to group 3\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Image classified as belonging to group 3\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "Image classified as belonging to group 1\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "Image classified as belonging to group 1\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Image classified as belonging to group 1\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "Image classified as belonging to group 3\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "Image classified as belonging to group 0\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "Image classified as belonging to group 0\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Image classified as belonging to group 1\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "Predicted class: Chaetoceros_sp_single, True class: Oscillatoriales\n",
            "Predicted class: Aphanothece_paralleliformis, True class: Uroglenopsis_sp\n",
            "Predicted class: Ceratoneis_closterium, True class: Cryptophyceae-Teleaulax\n",
            "Predicted class: Chroococcales, True class: Dolichospermum-Anabaenopsis-coiled\n",
            "Predicted class: Chlorococcales, True class: Dolichospermum-Anabaenopsis\n",
            "Predicted class: Centrales_sp, True class: Gymnodinium_like\n",
            "Predicted class: Aphanizomenon_flosaquae, True class: Aphanizomenon_flosaquae\n",
            "Predicted class: Ceratoneis_closterium, True class: Heterocapsa_triquetra\n",
            "Predicted class: Chroococcales, True class: Dolichospermum-Anabaenopsis-coiled\n",
            "Predicted class: Centrales_sp, True class: Cryptophyceae-Teleaulax\n",
            "Predicted class: Chlorococcales, True class: Dolichospermum-Anabaenopsis\n",
            "Predicted class: Chaetoceros_sp_single, True class: Oscillatoriales\n",
            "Predicted class: Chaetoceros_sp_single, True class: Oscillatoriales\n",
            "Predicted class: Ceratoneis_closterium, True class: Heterocapsa_triquetra\n",
            "Predicted class: Ceratoneis_closterium, True class: Cryptomonadales\n",
            "Predicted class: Chlorococcales, True class: Dolichospermum-Anabaenopsis\n",
            "Predicted class: Centrales_sp, True class: Oscillatoriales\n",
            "Predicted class: Chlorococcales, True class: Dolichospermum-Anabaenopsis\n",
            "Predicted class: Aphanizomenon_flosaquae, True class: Aphanizomenon_flosaquae\n",
            "Predicted class: Beads, True class: Cryptophyceae-Teleaulax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRuLMJEzyyWz"
      },
      "source": [
        "## Hyperparameter Tuning\n",
        "\n",
        "[Discuss any hyperparameter tuning methods you've applied, such as Grid Search or Random Search, and the rationale behind them.]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PGXT8LvqHzS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmNfCguKyyWz"
      },
      "outputs": [],
      "source": [
        "# Implement hyperparameter tuning\n",
        "# Example using GridSearchCV with a DecisionTreeClassifier\n",
        "# param_grid = {'max_depth': [2, 4, 6, 8]}\n",
        "# grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5)\n",
        "# grid_search.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57RoL7qbyyWz"
      },
      "source": [
        "## Implementation\n",
        "\n",
        "[Implement the final model(s) you've selected based on the above steps.]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILpPftnuyyWz"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvOBh8p3yyW0"
      },
      "source": [
        "## Evaluation Metrics\n",
        "\n",
        "[Clearly specify which metrics you'll use to evaluate the model performance, and why you've chosen these metrics.]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLGV13h7yyW0"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFD_PTwiyyW0"
      },
      "source": [
        "## Comparative Analysis\n",
        "\n",
        "[Compare the performance of your model(s) against the baseline model. Discuss any improvements or setbacks and the reasons behind them.]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_5hpqhVyyW0"
      },
      "outputs": [],
      "source": [
        "# Comparative Analysis code (if applicable)\n",
        "# Example: comparing accuracy of the baseline model and the new model\n",
        "# print(f\"Baseline Model Accuracy: {baseline_accuracy}, New Model Accuracy: {new_model_accuracy}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}